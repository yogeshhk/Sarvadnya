# import streamlit as st
# import os
# from rag import RAGChatbot
# from fine_tune import FineTuner
# import tempfile
# import shutil

# # Page configuration
# st.set_page_config(
#     page_title="Ask Vichar-Chitre Chatbot",
#     page_icon="üß†",
#     layout="wide"
# )

# # Initialize session state
# if 'rag_chatbot' not in st.session_state:
#     st.session_state.rag_chatbot = None
# if 'fine_tuner' not in st.session_state:
#     st.session_state.fine_tuner = None
# if 'chat_history' not in st.session_state:
#     st.session_state.chat_history = []
# if 'data_uploaded' not in st.session_state:
#     st.session_state.data_uploaded = False

# # Title and description
# st.title("üß† Ask Vichar-Chitre Chatbot")
# st.markdown("### ‡§Æ‡§æ‡§®‡§∏‡§ø‡§ï ‡§Æ‡•â‡§°‡•á‡§≤‡•ç‡§∏‡§µ‡§∞ ‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§Æ‡§∞‡§æ‡§†‡•Ä ‡§ö‡•Ö‡§ü‡§¨‡•â‡§ü")
# st.markdown("Mental Models chatbot in Marathi - Ask questions about cognitive biases, decision-making frameworks, and thinking patterns.")

# # Sidebar for configuration
# with st.sidebar:
#     st.header("‚öôÔ∏è Configuration")
    
#     # API Key input
#     groq_api_key = st.text_input("Groq API Key", type="password", 
#                                 help="Enter your Groq API key to use Gemma models")
    
#     if groq_api_key:
#         os.environ["GROQ_API_KEY"] = groq_api_key
    
#     # Model selection
#     model_type = st.selectbox(
#         "Select Model Type",
#         ["RAG with Raw Gemma", "RAG with Fine-tuned Gemma"],
#         help="Choose between raw Gemma model or fine-tuned version"
#     )
    
#     st.divider()
    
#     # Data upload section
#     st.header("üìÅ Data Upload")
#     uploaded_files = st.file_uploader(
#         "Upload Mental Models Data Files",
#         type=['txt', 'md', 'json'],
#         accept_multiple_files=True,
#         help="Upload text files containing mental models descriptions in Marathi"
#     )
    
#     if uploaded_files and groq_api_key:
#         if st.button("üîÑ Process Data & Initialize Chatbot"):
#             with st.spinner("Processing uploaded files..."):
#                 try:
#                     # Create temporary directory for uploaded files
#                     temp_dir = tempfile.mkdtemp()
                    
#                     # Save uploaded files
#                     for uploaded_file in uploaded_files:
#                         file_path = os.path.join(temp_dir, uploaded_file.name)
#                         with open(file_path, "wb") as f:
#                             f.write(uploaded_file.getbuffer())
                    
#                     # Initialize RAG chatbot
#                     st.session_state.rag_chatbot = RAGChatbot(
#                         data_directory=temp_dir,
#                         groq_api_key=groq_api_key
#                     )
                    
#                     # Initialize fine-tuner if needed
#                     if model_type == "RAG with Fine-tuned Gemma":
#                         st.session_state.fine_tuner = FineTuner(
#                             data_directory=temp_dir
#                         )
                    
#                     st.session_state.data_uploaded = True
#                     st.success("‚úÖ Data processed successfully!")
                    
#                 except Exception as e:
#                     st.error(f"‚ùå Error processing data: {str(e)}")
    
#     st.divider()
    
#     # Fine-tuning section
#     if model_type == "RAG with Fine-tuned Gemma" and st.session_state.data_uploaded:
#         st.header("üéØ Fine-tuning")
#         if st.button("üöÄ Start Fine-tuning"):
#             if st.session_state.fine_tuner:
#                 with st.spinner("Fine-tuning model... This may take a while."):
#                     try:
#                         st.session_state.fine_tuner.fine_tune_model()
#                         st.success("‚úÖ Model fine-tuned successfully!")
#                     except Exception as e:
#                         st.error(f"‚ùå Fine-tuning error: {str(e)}")
    
#     # Clear chat button
#     if st.button("üóëÔ∏è Clear Chat History"):
#         st.session_state.chat_history = []
#         st.rerun()

# # Main chat interface
# if not groq_api_key:
#     st.warning("‚ö†Ô∏è Please enter your Groq API key in the sidebar to get started.")
# elif not st.session_state.data_uploaded:
#     st.info("üìÅ Please upload data files and initialize the chatbot using the sidebar.")
# else:
#     # Chat interface
#     st.header("üí¨ Chat Interface")
    
#     # Display chat history
#     for i, (question, answer) in enumerate(st.session_state.chat_history):
#         with st.container():
#             st.markdown(f"**üë§ You:** {question}")
#             st.markdown(f"**ü§ñ Vichar-Chitre:** {answer}")
#             st.divider()
    
#     # Input for new question
#     user_question = st.text_input(
#         "‡§Ü‡§™‡§≤‡§æ ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§Æ‡§∞‡§æ‡§†‡•Ä‡§§ ‡§µ‡§ø‡§ö‡§æ‡§∞‡§æ / Ask your question in Marathi:",
#         placeholder="‡§â‡§¶‡§æ: Sunk cost fallacy ‡§Ø‡§æ mental model ‡§≤‡§æ ‡§Æ‡§∞‡§æ‡§†‡•Ä‡§§ ‡§ï‡§æ‡§Ø ‡§Æ‡•ç‡§π‡§£‡§æ‡§§‡§æ‡§§ ‡§Ü‡§£‡§ø ‡§§‡•ç‡§Ø‡§æ‡§ö‡•á ‡§â‡§¶‡§æ‡§π‡§∞‡§£ ‡§¶‡•ç‡§Ø‡§æ",
#         key="user_input"
#     )
    
#     col1, col2 = st.columns([1, 4])
    
#     with col1:
#         ask_button = st.button("üöÄ Ask Question", type="primary")
    
#     with col2:
#         if st.button("üìù Example Questions"):
#             st.info("""
#             **Example Questions:**
#             - Sunk cost fallacy ‡§Ø‡§æ mental model ‡§≤‡§æ ‡§Æ‡§∞‡§æ‡§†‡•Ä‡§§ ‡§ï‡§æ‡§Ø ‡§Æ‡•ç‡§π‡§£‡§æ‡§§‡§æ‡§§ ‡§Ü‡§£‡§ø ‡§§‡•ç‡§Ø‡§æ‡§ö‡•á ‡§â‡§¶‡§æ‡§π‡§∞‡§£ ‡§¶‡•ç‡§Ø‡§æ
#             - Confirmation bias ‡§¨‡§¶‡•ç‡§¶‡§≤ ‡§Æ‡§∞‡§æ‡§†‡•Ä‡§§ ‡§∏‡§æ‡§Ç‡§ó‡§æ
#             - Decision making ‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§ï‡•ã‡§£‡§§‡•á mental models ‡§µ‡§æ‡§™‡§∞‡§æ‡§µ‡•á?
#             - Anchoring bias ‡§Æ‡•ç‡§π‡§£‡§ú‡•á ‡§ï‡§æ‡§Ø?
#             """)
    
#     if ask_button and user_question:
#         if st.session_state.rag_chatbot:
#             with st.spinner("Thinking... ‡§µ‡§ø‡§ö‡§æ‡§∞ ‡§ï‡§∞‡§§ ‡§Ü‡§π‡•á..."):
#                 try:
#                     # Get response based on model type
#                     if model_type == "RAG with Fine-tuned Gemma" and st.session_state.fine_tuner:
#                         # Use fine-tuned model if available
#                         response = st.session_state.rag_chatbot.get_response_with_finetuned(
#                             user_question, 
#                             st.session_state.fine_tuner.model
#                         )
#                     else:
#                         # Use raw model with RAG
#                         response = st.session_state.rag_chatbot.get_response(user_question)
                    
#                     # Add to chat history
#                     st.session_state.chat_history.append((user_question, response))
                    
#                     # Display the new response
#                     with st.container():
#                         st.markdown(f"**üë§ You:** {user_question}")
#                         st.markdown(f"**ü§ñ Vichar-Chitre:** {response}")
                    
#                     st.rerun()
                    
#                 except Exception as e:
#                     st.error(f"‚ùå Error generating response: {str(e)}")
#         else:
#             st.error("‚ùå Chatbot not initialized. Please upload data first.")

# # Footer
# with st.container():
#     st.divider()
#     st.markdown("""
#     <div style='text-align: center; color: #666; font-size: 0.8em;'>
#         üß† Ask Vichar-Chitre Chatbot | Powered by Gemma & LlamaIndex | Built with Streamlit
#     </div>
#     """, unsafe_allow_html=True)
# import os
# import streamlit as st
# from dotenv import load_dotenv
# from rag_module import RAGChatbot

# # Load environment variables from .env file
# load_dotenv()
# groq_api_key = os.getenv("GROQ_API_KEY")

# if "rag_chatbot" not in st.session_state:
#     st.session_state.rag_chatbot = RAGChatbot(data_directory="data", groq_api_key=groq_api_key)

# # Streamlit App UI
# st.set_page_config(page_title="üß† Vichar-Chitre", layout="wide")
# st.title("üß† ‡§µ‡§ø‡§ö‡§æ‡§∞-‡§ö‡§ø‡§§‡•ç‡§∞‡•á Chatbot (Marathi RAG)")

# # Sidebar
# st.sidebar.header("‚öôÔ∏è Settings")
# uploaded_files = st.sidebar.file_uploader(
#     "üìÅ Upload .txt or .md files", type=["txt", "md"], accept_multiple_files=True
# )

# if "bot" not in st.session_state:
#     st.session_state.bot = None
# if "history" not in st.session_state:
#     st.session_state.history = []

# if st.sidebar.button("üîÑ Process Data & Initialize Chatbot"):
#     if not groq_api_key:
#         st.sidebar.error("‚ùå GROQ_API_KEY not found in environment.")
#     else:
#         with st.spinner("üîß Initializing RAG Chatbot..."):
#             data_folder = "data"
#             os.makedirs(data_folder, exist_ok=True)

#             for file in uploaded_files:
#                 file_path = os.path.join(data_folder, file.name)
#                 with open(file_path, "wb") as f:
#                     f.write(file.getbuffer())

#             try:
#                 st.session_state.bot = RAGChatbot(data_directory=data_folder, groq_api_key=groq_api_key)
#                 st.success("‚úÖ RAG Chatbot ready!")
#             except Exception as e:
#                 st.error(f"‚ùå Error: {e}")

# # Chat UI
# if st.session_state.bot:
#     user_input = st.text_input("‡§§‡•Å‡§Æ‡§ö‡§æ ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§µ‡§ø‡§ö‡§æ‡§∞‡§æ‡§É", key="input")

#     if st.button("üì® Send"):
#         if user_input:
#             with st.spinner("‚úçÔ∏è Generating Answer..."):
#                 try:
#                     response = st.session_state.bot.get_response(user_input)
#                     st.session_state.history.append(("‡§§‡•Å‡§Æ‡§ö‡§æ ‡§™‡•ç‡§∞‡§∂‡•ç‡§®", user_input))
#                     st.session_state.history.append(("‡§¨‡•â‡§ü‡§ö‡•á ‡§â‡§§‡•ç‡§§‡§∞", response))
#                 except Exception as e:
#                     st.error(f"‚ùå Error: {e}")

# # Chat History Display
# if st.session_state.history:
#     st.markdown("---")
#     st.subheader("üìú Chat History")
#     for speaker, message in st.session_state.history:
#         st.markdown(f"**{speaker}:** {message}")

import os
import streamlit as st
from dotenv import load_dotenv
from rag_gemma import RAGChatbot

# Load environment variables
load_dotenv()
groq_api_key = os.getenv("GROQ_API_KEY")

# Set up session state
if "bot" not in st.session_state:
    st.session_state.bot = None
if "history" not in st.session_state:
    st.session_state.history = []

# Page Config
st.set_page_config(page_title="üß† Vichar-Chitre", layout="wide")
st.title("üß† ‡§µ‡§ø‡§ö‡§æ‡§∞-‡§ö‡§ø‡§§‡•ç‡§∞‡•á Chatbot (Marathi RAG)")

# Sidebar for file upload
st.sidebar.header("‚öôÔ∏è Settings")
uploaded_files = st.sidebar.file_uploader(
    "üìÅ Upload .txt, .md or .tex files",
    type=["txt", "md", "tex"],
    accept_multiple_files=True
)

if st.sidebar.button("üîÑ Process Data & Initialize Chatbot"):
    with st.spinner("üîß Initializing RAG Chatbot..."):
        data_folder = "data"
        os.makedirs(data_folder, exist_ok=True)

        for file in uploaded_files:
            file_path = os.path.join(data_folder, file.name)
            with open(file_path, "wb") as f:
                f.write(file.getbuffer())

        try:
            st.session_state.bot = RAGChatbot(data_directory=data_folder, groq_api_key=groq_api_key)
            st.success("‚úÖ RAG Chatbot is ready to chat!")
        except Exception as e:
            st.error(f"‚ùå Error during initialization: {e}")
            
if st.session_state.bot:
    user_input = st.text_input("‡§§‡•Å‡§Æ‡§ö‡§æ ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§µ‡§ø‡§ö‡§æ‡§∞‡§æ‡§É", key="input")

    if st.button("üì® Send") and user_input:
        with st.spinner("‚úçÔ∏è Generating Answer..."):
            try:
                response = st.session_state.bot.get_response(user_input)

                # Handle structured vs raw response
                if isinstance(response, dict):
                    answer = response.get("answer", "").strip()
                    context = response.get("context", "").strip()
                else:
                    answer = str(response).strip()
                    context = ""

                # Handle empty answer gracefully
                if not answer:
                    if context:
                        answer = "‚ö†Ô∏è Context found but no specific answer was generated."
                    else:
                        answer = "‚ö†Ô∏è Sorry, I couldn't find the answer in the uploaded document."

                # Save chat history
                full_response = answer
                if context:
                    full_response += f"\n\nüìé Retrieved Context:\n{context}"

                st.session_state.history.append(("‡§§‡•Å‡§Æ‡§ö‡§æ ‡§™‡•ç‡§∞‡§∂‡•ç‡§®", user_input))
                st.session_state.history.append(("‡§¨‡•â‡§ü‡§ö‡•á ‡§â‡§§‡•ç‡§§‡§∞", full_response))

                # Display current response
                st.markdown(f"**‡§¨‡•â‡§ü‡§ö‡•á ‡§â‡§§‡•ç‡§§‡§∞:** {answer}")
                if context:
                    st.markdown("üß© **Retrieved Context from Document:**")
                    st.code(context)

            except Exception as e:
                st.error(f"‚ùå Error while generating answer: {e}")

# Display Chat History
if st.session_state.history:
    st.markdown("---")
    st.subheader("üìú Chat History")
    for speaker, message in st.session_state.history:
        st.markdown(f"**{speaker}:** {message}")